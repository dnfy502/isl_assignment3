{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0921550",
   "metadata": {},
   "source": [
    "# Question 1: Bayes Classifier\n",
    "Implement Bayes classifier for three datasets under four covariance assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8559d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Utility: load class data from text file\n",
    "def load_class_data(path, label):\n",
    "    data = np.loadtxt(path)  # two columns\n",
    "    labels = np.full((data.shape[0],), label)\n",
    "    return data, labels\n",
    "\n",
    "# Utility: split each class into train and test sets (70/30)\n",
    "def split_data(X, y, test_size=0.3, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, stratify=y, random_state=random_state)\n",
    "\n",
    "# Estimate Gaussian parameters for each class\n",
    "def estimate_parameters(X, y):\n",
    "    classes = np.unique(y)\n",
    "    params = {}\n",
    "    for c in classes:\n",
    "        Xc = X[y==c]\n",
    "        mu = Xc.mean(axis=0)\n",
    "        cov = np.cov(Xc, rowvar=False)\n",
    "        params[c] = {'mu': mu, 'cov': cov}\n",
    "    return params\n",
    "\n",
    "# Gaussian density\n",
    "def gaussian_pdf(x, mu, cov):\n",
    "    d = len(mu)\n",
    "    det = np.linalg.det(cov)\n",
    "    inv = np.linalg.inv(cov)\n",
    "    norm = 1 / np.sqrt((2*np.pi)**d * det)\n",
    "    diff = x - mu\n",
    "    return norm * np.exp(-0.5 * diff @ inv @ diff.T)\n",
    "\n",
    "# Bayes classifier general function\n",
    "def predict_bayes(X, params, priors, cov_type='class_full', sigma2=None, shared_cov=None):\n",
    "    # cov_type: 'spherical', 'shared_full', 'class_diag', 'class_full'\n",
    "    classes = list(params.keys())\n",
    "    y_pred = []\n",
    "    for x in X:\n",
    "        post = []\n",
    "        for c in classes:\n",
    "            mu = params[c]['mu']\n",
    "            if cov_type=='spherical': cov = sigma2 * np.eye(len(mu))\n",
    "            elif cov_type=='shared_full': cov = shared_cov\n",
    "            elif cov_type=='class_diag': cov = np.diag(np.diag(params[c]['cov']))\n",
    "            else: cov = params[c]['cov']\n",
    "            post.append(priors[c] * gaussian_pdf(x, mu, cov))\n",
    "        y_pred.append(classes[np.argmax(post)])\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Common function to evaluate and plot Bayes classifier for a dataset\n",
    "def run_dataset(name, X, y):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    # estimate parameters\n",
    "    params = estimate_parameters(X_train, y_train)\n",
    "    # compute class priors\n",
    "    priors = {c: np.mean(y_train==c) for c in params}\n",
    "    # spherical variance\n",
    "    sigmas = [np.mean(np.diag(params[c]['cov'])) for c in params]\n",
    "    sigma2 = np.mean(sigmas)\n",
    "    # shared full covariance\n",
    "    shared_cov = sum(params[c]['cov'] for c in params) / len(params)\n",
    "    types = [\n",
    "        ('spherical', {'sigma2': sigma2}),\n",
    "        ('shared_full', {'shared_cov': shared_cov}),\n",
    "        ('class_diag', {}),\n",
    "        ('class_full', {})\n",
    "    ]\n",
    "    print(f'\\n=== {name} ===')\n",
    "    for cov_type, kwargs in types:\n",
    "        y_pred = predict_bayes(X_test, params, priors, cov_type=cov_type, **kwargs)\n",
    "        print(f'-- {cov_type} --')\n",
    "        print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "        print('Precision:', precision_score(y_test, y_pred, average=None))\n",
    "        print('Recall:', recall_score(y_test, y_pred, average=None))\n",
    "        print('F1:', f1_score(y_test, y_pred, average=None))\n",
    "        print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2edd8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Linearly separable ===\n",
      "-- spherical --\n",
      "Accuracy: 1.0\n",
      "Precision: [1. 1. 1.]\n",
      "Recall: [1. 1. 1.]\n",
      "F1: [1. 1. 1.]\n",
      "Confusion matrix:\n",
      " [[150   0   0]\n",
      " [  0 150   0]\n",
      " [  0   0 150]]\n",
      "-- shared_full --\n",
      "Accuracy: 1.0\n",
      "Precision: [1. 1. 1.]\n",
      "Recall: [1. 1. 1.]\n",
      "F1: [1. 1. 1.]\n",
      "Confusion matrix:\n",
      " [[150   0   0]\n",
      " [  0 150   0]\n",
      " [  0   0 150]]\n",
      "-- class_diag --\n",
      "Accuracy: 1.0\n",
      "Precision: [1. 1. 1.]\n",
      "Recall: [1. 1. 1.]\n",
      "F1: [1. 1. 1.]\n",
      "Confusion matrix:\n",
      " [[150   0   0]\n",
      " [  0 150   0]\n",
      " [  0   0 150]]\n",
      "-- class_full --\n",
      "Accuracy: 1.0\n",
      "Precision: [1. 1. 1.]\n",
      "Recall: [1. 1. 1.]\n",
      "F1: [1. 1. 1.]\n",
      "Confusion matrix:\n",
      " [[150   0   0]\n",
      " [  0 150   0]\n",
      " [  0   0 150]]\n"
     ]
    }
   ],
   "source": [
    "# Dataset 1: Linearly separable classes\n",
    "files = ['LS_Group12/Class1.txt', 'LS_Group12/Class2.txt', 'LS_Group12/Class3.txt']\n",
    "X1 = np.vstack([load_class_data(f, i)[0] for i,f in enumerate(files)])\n",
    "y1 = np.concatenate([load_class_data(f, i)[1] for i,f in enumerate(files)])\n",
    "run_dataset('Linearly separable', X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa5cabf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'First'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([np\u001b[38;5;241m.\u001b[39mfull(c, i) \u001b[38;5;28;01mfor\u001b[39;00m i, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(counts)])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n\u001b[0;32m----> 8\u001b[0m X2, y2 \u001b[38;5;241m=\u001b[39m \u001b[43mload_nls_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNLS_Group12.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m run_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNonlinearly separable\u001b[39m\u001b[38;5;124m'\u001b[39m, X2, y2)\n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36mload_nls_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_nls_data\u001b[39m(path):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path) \u001b[38;5;28;01mas\u001b[39;00m f: counts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(path, skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m     X \u001b[38;5;241m=\u001b[39m data[:, :\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'First'"
     ]
    }
   ],
   "source": [
    "# Dataset 2: Nonlinearly separable classes\n",
    "def load_nls_data(path):\n",
    "    with open(path) as f: counts = list(map(int, f.readline().split()))\n",
    "    data = np.loadtxt(path, skiprows=1)\n",
    "    X = data[:, :2]\n",
    "    y = np.concatenate([np.full(c, i) for i, c in enumerate(counts)])\n",
    "    return X, y\n",
    "X2, y2 = load_nls_data('NLS_Group12.txt')\n",
    "run_dataset('Nonlinearly separable', X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b84c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 3: Real-world vowel data\n",
    "files = ['rd_group12/class1.txt', 'rd_group12/class2.txt', 'rd_group12/class3.txt']\n",
    "X3 = np.vstack([load_class_data(f, i)[0] for i,f in enumerate(files)])\n",
    "y3 = np.concatenate([load_class_data(f, i)[1] for i,f in enumerate(files)])\n",
    "run_dataset('Vowel data', X3, y3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
